{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "624eea49-7a7e-405b-b55e-9b4c35954dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WyWZmKrerIoFUwSGit3PFsmZPJvB0kVkEpcgrZZd\n"
     ]
    }
   ],
   "source": [
    "# Importación de librerias y uso de Api key de Cohere\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import cohere\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "\n",
    "COHERE_API_KEY = os.getenv(\"API_KEY\")\n",
    "#print(COHERE_API_KEY)  # Verify the key\n",
    "\n",
    "co = cohere.ClientV2(COHERE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cada78d-c399-4ddd-9905-1b22039e07fb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto combinado del PDF:\n",
      "Sol y Luna \n",
      "Sol y Luna eran dos pequeños gatitos que habían nacido en la misma camada, pero sus \n",
      "personalidades no podían ser más diferentes. Sol, de un brillante color anaranjado, era \n",
      "aventurero y c\n",
      "\n",
      "Número de páginas: 3\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "## Extracción de texto de archivo PDF.\n",
    "\n",
    "# Función para extraer el texto de un archivo pdf\n",
    "def extract_text_from_pdf(file_path):\n",
    "    \"\"\"\n",
    "        1-Extrae el texto de las páginas del archivo.pdf\n",
    "        2-Parámetros\n",
    "            - file_path(String): Ruta del archivo PDF\n",
    "        3-Retorna\n",
    "            -combined_text(String) : texto de todas las páginas\n",
    "            -page_texts(list) : Lista con el texto de cada una de las páginas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Cargar el documento pdf con el nombre de su ruta\n",
    "        reader = PdfReader(file_path)\n",
    "        \n",
    "        # Extraer texto de todas las páginas\n",
    "        page_texts = [page.extract_text() for page in reader.pages]\n",
    "\n",
    "        # Combinar todas las páginas en un solo texto\n",
    "        combined_text = \"\\n\".join(page_texts)\n",
    "\n",
    "        return combined_text, page_texts\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        # Manejo del error en caso que  no exista el archivo\n",
    "        print(f\"Error: el archivo solicitado '{file_path}' no fue encontrado.\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        # Manejo de cualquier otro tipo de error\n",
    "        print(f\"Error al leer el archivo PDF: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Ejemplo de uso de la funcion -extract_text_from_pdf- para probar la extracción de texto\n",
    "pdf_path = 'historias.pdf' #Ruta del archivo\n",
    "combined_text, page_texts = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "if combined_text:\n",
    "    print(\"Texto combinado del PDF:\")\n",
    "    # Mostrar solo una parte del texto combinado para evitar sobrecarga en la salida\n",
    "    print(combined_text[:200])  #Ej: Muestra los primeros 200 caracteres\n",
    "    print(\"\\nNúmero de páginas:\", len(page_texts)) #Número total de páginas\n",
    "else:\n",
    "    print(\"No fue posible extraer el texto del archivo PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1d065c5-0ef8-4ea4-80c3-3f6f77626306",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historia dividida en 17 chunks:\n",
      "Chunk 1 (356 caracteres):\n",
      "Sol y Luna \n",
      "Sol y Luna eran dos pequeños gatitos que habían nacido en la misma camada, pero sus \n",
      "personalidades no podían ser más diferentes. Sol, de un brillante color anaranjado, era \n",
      "aventurero y curioso; siempre buscando nuevas experiencias y explorando cada rincón de \n",
      "su hogar. Luna, en cambio, era de un suave pelaje gris y tenía un temperamento más\n",
      "\n",
      "Chunk 2 (310 caracteres):\n",
      "sereno y observador. Pasaba horas contemplando el mundo desde la ventana, como si en \n",
      "cada sombra descubriera un misterio oculto. \n",
      "Una tarde, mientras Sol correteaba por el jardín persiguiendo mariposas, Luna permanecía \n",
      "en el alféizar, vigilando desde lejos. De repente, una fuerte tormenta comenzó a formarse\n",
      "\n",
      "Chunk 3 (318 caracteres):\n",
      "en el horizonte. El viento sacudía las ramas de los árboles, y las gotas de lluvia empezaron \n",
      "a caer pesadamente. Sol, atrapado por su espíritu inquieto, no se dio cuenta de lo rápido \n",
      "que se acercaba la tormenta. Luna, desde su posición, sintió una inquietud que la hizo \n",
      "saltar del alféizar y correr hacia la puerta.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Primer paso: Configuración de la división del texto en chunks utilizando\n",
    "# RecursiveCharacterTextSplitter de Langchain\n",
    "\n",
    "text_splitter= RecursiveCharacterTextSplitter(\n",
    "    chunk_size= 400, #Define el número de máximo de caracteres por chunk,Con 400 caracteres, mantiene oraciones completas, coherentes, y para   #ser manejada por algoritmos de busqueda como en este caso(generación de vector) para almacenar en ChromaDB.\n",
    "    chunk_overlap= 50 #Indica la Superposición de 50 caracteres entre chunks, este valor garantiza que las transiciones entre ellos sean suaves, asegurando que no se pierda información entre cada solapamiento.\n",
    ")\n",
    "\n",
    "# Paso 2: Texto para dividir en chunks, utilizo el texto combinado obtenido de la extracción del pdf\n",
    "historia= combined_text\n",
    "\n",
    "# Paso 3: Crear los chunks(con previa validación) a partir del texto con la configuración ya definida.\n",
    "if not historia.strip():\n",
    "    print(\"El texto está vacío o no contiene contenido relevante para dividir.\")\n",
    "else:\n",
    "    chunks = text_splitter.split_text(historia)\n",
    "\n",
    "# Paso 4: Obtener los resultados impresos en pantalla\n",
    "\n",
    "print(f\"Historia dividida en {len(chunks)} chunks:\")\n",
    "for i, chunk in enumerate(chunks[:3]): #Ej, mostrar una cantidad limitada para no sobrecargar la salida\n",
    "    print(f\"Chunk {i + 1} ({len(chunk)} caracteres):\\n{chunk}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c68f128b-c4d0-435e-9a65-955222e123cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generados 17 embeddings para los 17 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import CohereEmbeddings\n",
    "\n",
    "# Paso 1: Generación de embeddings para los chunks\n",
    "\n",
    "# Utilicé el modelo de embed-multilingual-v3.0 para crear las representaciones vectoriales\n",
    "# de cada chunk de texto. Estos embeddings se utilizaran para futuras búsquedas.\n",
    "\n",
    "response = co.embed(\n",
    "    texts= chunks, #Lista de chucnks para procesar\n",
    "    model= \"embed-multilingual-v3.0\", # Modelo de embeddings multilingüe\n",
    "    input_type=\"search_document\",\n",
    "    embedding_types=[\"float\"],\n",
    ")\n",
    "# Paso 2: Obtención de los embeddings generados, se extraen como vectores flotantes.\n",
    "embeddings= response.embeddings.float_\n",
    "\n",
    "# Verificar la generación de los embeddings\n",
    "if embeddings and len(embeddings) == len(chunks):\n",
    "     print(f\"Generados {len(embeddings)} embeddings para los {len(chunks)} chunks.\")\n",
    "else:\n",
    "      print(\"Error: No fue posible generar los embeddings o el número de embeddings no coincide con los chunks.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463c1324-34d3-4d4b-b037-5f899db03b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings y chunks guardados exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# Importación de libreria para manejar archivos JSON\n",
    "import json \n",
    "\n",
    "# Paso 1: Asociar cada chunk con su embedding correspondiente\n",
    "# Lista de diccionarios donde se encuentra el texto del chunk y su vector correspondiente.\n",
    "data = [{\"id\": i + 1, \"chunk\": chunk, \"embedding\": embedding} for i, (chunk, embedding) in enumerate(zip(chunks, embeddings))]\n",
    "\n",
    "# Paso 2: Extraer por separado de cada los chunks y embeddings para uso posterior\n",
    "documents = [item[\"chunk\"] for item in data]  # Extraer los textos (chunks)\n",
    "embeddings = [item[\"embedding\"] for item in data]  # Extraer los embeddings\n",
    "\n",
    "# Paso 3: Guardar los datos en un archivo JSON para tener un acceso facil y reutilizable,\n",
    "# previamente validando que la cantidad de chunks y embeddings sean iguales.\n",
    "if len(chunks) != len(embeddings):\n",
    "    print(\"Error: El número de chunks no coincide con el número de embeddings.\")\n",
    "else:\n",
    "   try:\n",
    "       with open(\"embeddings.json\", \"w\") as f:\n",
    "           json.dump(data, f)\n",
    "           print(\"Embeddings y chunks guardados exitosamente.\")\n",
    "   except Exception as e:\n",
    "        print(f\"Error al guardar los embeddings: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "777f6168-3e69-4521-8cc4-4d30b7865179",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: id_0\n",
      "Add of existing embedding ID: id_1\n",
      "Add of existing embedding ID: id_2\n",
      "Add of existing embedding ID: id_3\n",
      "Add of existing embedding ID: id_4\n",
      "Add of existing embedding ID: id_5\n",
      "Add of existing embedding ID: id_6\n",
      "Add of existing embedding ID: id_7\n",
      "Add of existing embedding ID: id_8\n",
      "Add of existing embedding ID: id_9\n",
      "Add of existing embedding ID: id_10\n",
      "Add of existing embedding ID: id_11\n",
      "Add of existing embedding ID: id_12\n",
      "Add of existing embedding ID: id_13\n",
      "Add of existing embedding ID: id_14\n",
      "Add of existing embedding ID: id_15\n",
      "Add of existing embedding ID: id_16\n",
      "Insert of existing embedding ID: id_0\n",
      "Insert of existing embedding ID: id_1\n",
      "Insert of existing embedding ID: id_2\n",
      "Insert of existing embedding ID: id_3\n",
      "Insert of existing embedding ID: id_4\n",
      "Insert of existing embedding ID: id_5\n",
      "Insert of existing embedding ID: id_6\n",
      "Insert of existing embedding ID: id_7\n",
      "Insert of existing embedding ID: id_8\n",
      "Insert of existing embedding ID: id_9\n",
      "Insert of existing embedding ID: id_10\n",
      "Insert of existing embedding ID: id_11\n",
      "Insert of existing embedding ID: id_12\n",
      "Insert of existing embedding ID: id_13\n",
      "Insert of existing embedding ID: id_14\n",
      "Insert of existing embedding ID: id_15\n",
      "Insert of existing embedding ID: id_16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos y embeddings añadidos correctamente a la colección 'text_chunks'.\n",
      "Estado de la colección 'text_chunks': Collection(name=text_chunks)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Collection(name=text_chunks)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación de Chromadb.\n",
    "import chromadb\n",
    "# Creación de un cliente para realizar la conexión a la base de datos vectorial\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# Crear o recuperar si ya existe una colección en ChromaDB (con el método get_or_create_collection)\n",
    "collection_name = \"text_chunks\"\n",
    "collection = chroma_client.get_or_create_collection(collection_name)\n",
    "\n",
    "# Verificar la correspondencia entre documentos y embeddings\n",
    "if len(documents) == len(embeddings):\n",
    "\n",
    "    # Generar IDs dinámicamente segun la cantidad de chunks\n",
    "    ids = [f\"id_{i}\" for i in range(len(documents))]\n",
    "    try:\n",
    "        collection.add(\n",
    "            documents=documents,  # Lista de textos(chunks)\n",
    "            embeddings=embeddings,  # Lista de embeddings correspondientes\n",
    "            ids=ids  # Lista de IDs generados\n",
    "        )\n",
    "        print(f\"Documentos y embeddings añadidos correctamente a la colección '{collection_name}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al añadir documentos y embeddings a la colección: {e}\")\n",
    "else:\n",
    "    # Manejo del error en caso que las longitudes sean diferentes\n",
    "    print(f\"Error: La cantidad de chunks ({len(documents)}) no coincide con la cantidad de embeddings ({len(embeddings)}).\")\n",
    "    \n",
    "# Mostrar la colección para confirmar el estado\n",
    "print(f\"Estado de la colección '{collection_name}': {collection}\")\n",
    "\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0524f948-4af3-46c0-8ebe-da2f773a2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Funciones independientes para generación de embeddings de prompts, búsqueda en base de datos y generación de respuesta.\n",
    "\n",
    "# Función para generar el embedding para el prompt\n",
    "\n",
    "def generar_embedding_prompt(prompt_text):\n",
    "    \"\"\"\n",
    "        -La función genera el embedding para un texto dado utilizando el modelo de Cohere\n",
    "        -Parámetros prompt_text(String):Texto para el cual se generará el embedding.\n",
    "        -La función retorna el embedding generado como una lista de elementos flotantes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = co.embed(\n",
    "            texts=[prompt_text],\n",
    "            model=\"embed-multilingual-v3.0\",\n",
    "            input_type=\"search_document\",\n",
    "            embedding_types=[\"float\"]\n",
    "        )\n",
    "        return response.embeddings.float_[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error al generar el embedding del prompt: {e}\")\n",
    "        return \"Hubo un problema al generar los embeddings. Intenta nuevamente.\"\n",
    "\n",
    "# Funcion para búsqueda en base de datos Chromadb\n",
    "def busqueda_en_chromadb(prompt_text):\n",
    "    \"\"\"\n",
    "        -La función busca documentos relevantes en ChromaDB utilizando el embedding del prompt.\n",
    "        -Parámetros prompt_text(String):Texto del prompt a buscar.\n",
    "        -La función retorna el el documento relevante más cercando al embedding del prompt, \n",
    "        o retorna None si no encuentra un documento relevante.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generar el embedding del prompt\n",
    "        prompt_embedding = generar_embedding_prompt(prompt_text)\n",
    "        if not prompt_embedding:\n",
    "            return None\n",
    "        \n",
    "        # Consulta en la colección en ChromaDB.\n",
    "        resultados = collection.query(\n",
    "            query_embeddings=[prompt_embedding],  # Embedding del prompt\n",
    "            n_results=1  # Número de resultados a recuperar\n",
    "        )\n",
    "         # Devolver el documento más relevante si existe\n",
    "        return resultados['documents'][0] if resultados['documents'] else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error al buscar en ChromaDB: {e}\")\n",
    "        return None\n",
    "    \n",
    "# Función para generar una respuesta final utilizando Cohere     \n",
    "def generar_respuesta_final(documento_relevante, pregunta, system_prompt):\n",
    "    \"\"\"\n",
    "        -La función genera una respuesta basada en el contenido de un documento y un prompt proporcionado.\n",
    "        -Parámetros:\n",
    "            documento(String): Texto relevante recuperado de la base de datos.\n",
    "            pregunta (String Pregunta del usuario.\n",
    "            system_prompt (String): Instrucciones para el modelo de generación de texto.\n",
    "        - Respuesta generada o mensaje de error si no hay documentos relevantes.\n",
    "    \"\"\"\n",
    "    \n",
    "    if documento_relevante:\n",
    "        try:\n",
    "            # Preparar el prompt para la generación de respuesta\n",
    "            prompt_con_instrucciones = f\"{system_prompt}\\nTexto relevante: {documento_relevante}\\n\\nPregunta: {pregunta}\"\n",
    "            \n",
    "            #Generación de la respuesta utilizando un modelo de Cohere\n",
    "            response = co.generate(\n",
    "                model=\"command-r-plus-08-2024\", \n",
    "                prompt=prompt_con_instrucciones,\n",
    "                max_tokens=100,\n",
    "                temperature=0.2, \n",
    "            )\n",
    "            return response.generations[0].text.strip() \n",
    "        except Exception as e:\n",
    "            print(f\"Error al generar la respuesta con Cohere: {e}\")\n",
    "            return \"Hubo un problema al generar la respuesta. Por favor, intenta nuevamente.\"\n",
    "    else:\n",
    "        return \"No se encontraron resultados relevantes para tu pregunta.\"\n",
    "        \n",
    "# Definir el system prompt con las instrucciones\n",
    "system_prompt = \"\"\"\n",
    "Tu trabajo es responder a las preguntas, con las siguientes características:\n",
    "- Responde de manera amigable y con tono entusiasta, como si le hablaras a un niño.\n",
    "- Responde en máximo 3 oraciones.\n",
    "- Agrega emojis a la respuesta.\n",
    "- Ante la misma pregunta debes responder lo más similar posible para cada interacción.\n",
    "- Responde siempre en español, sin importar en qué idioma se haga la pregunta.\n",
    "- Solo debes utilizar el contenido de las historias para responder sobre las preguntas del usuario.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8815a25-fede-413d-817d-a3ab15d5e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implementación de RAG_answer\n",
    "# Función para generar el embedding para el prompt\n",
    "\n",
    "def RAG_answer(prompt, collection, system_prompt):\n",
    "    \"\"\"\n",
    "    Realiza el flujo RAG (Retrieve, Answer, Generate) en una sola función:\n",
    "    1. Generar embedding del prompt (Llamada a su función correspondiente)\n",
    "    2. Buscar en la base de datos el documento más relevante.(Llamada a su función correspondiente)\n",
    "    3. Generar una respuesta basada en el documento y el prompt.(Llamada a su función correspondiente)\n",
    "\n",
    "    Parámetros:\n",
    "        prompt (String): La pregunta del usuario.\n",
    "        collection: Base de datos vectorial (ChromaDB).\n",
    "        system_prompt (String): Instrucciones para el modelo de generación de texto.\n",
    "\n",
    "    Retorna:\n",
    "        str: La respuesta generada o un mensaje de error si ocurre algo inesperado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Paso 1: Generar el embedding del prompt\n",
    "        prompt_embedding = generar_embedding_prompt(prompt)\n",
    "        if not prompt_embedding:\n",
    "            return \"Hubo un problema al generar los embeddings. Intenta nuevamente.\"\n",
    "\n",
    "        # Paso 2: Buscar en la base de datos el documento más relevante\n",
    "        documento_relevante = busqueda_en_chromadb(prompt)\n",
    "        if not documento_relevante:\n",
    "            return \"No se encontraron resultados relevantes para tu pregunta.\"\n",
    "            \n",
    "        # Paso 3: Generar la respuesta final utilizando el documento relevante utilizando un modelo de Cohere\n",
    "        response= generar_respuesta_final(documento_relevante,prompt,system_prompt)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error en el flujo RAG: {e}\")\n",
    "        return \"Ocurrió un error al procesar tu pregunta. Intenta nuevamente.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b96ce4fa-a04e-4535-b103-0dd6e334c96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌞 Sol y 🌙 Luna son dos amigos muy especiales, ¡como el día y la noche! Juntos descubrieron que su amistad es más poderosa que cualquier diferencia. 😊🤗\n"
     ]
    }
   ],
   "source": [
    "#Uso - prueba 1 - Historia Sol y Luna\n",
    "#Definición del prompt\n",
    "prompt = \"¿Quiénes son Sol y luna?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7807c91-97b3-4684-88bd-608411d3fc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌧️ ¡Oh, una tarde lluviosa! Sol estaba jugando en el jardín y de repente se encontró solo bajo la lluvia, sintiendo un poquito de miedo porque todo se volvió oscuro y extraño. ¡Pero estoy seguro de que pronto encontró un lugar cálido y seco! 😺🌈\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 2 - Historia Sol y Luna\n",
    "\n",
    "prompt = \"¿Qué pasó una tarde mientras Sol corría en el jardin?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c075b936-bf40-48f8-a634-9b750fa408d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌞 ¡Qué historia tan emocionante! Cuando Sol y Luna regresaban a casa, se sentaron cerca del fuego y Sol se quedó dormidito, mientras Luna lo cuidaba con mucho amor. 💕🌙 ¡Qué lindo vínculo tienen!\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 3 - Historia Sol y Luna\n",
    "\n",
    "prompt = \"¿Qué pasó cuando Sol y Luna regresaban a su casa?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b8c73002-9b30-488a-8e9f-2e98533e40ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Los gatitos nos enseñan que la diversión es mejor cuando se comparte con amabilidad y amor! 😻🌟 Recuerda siempre ser amable y respetuoso con los demás, así tendrás amigos felices y risas sin fin. 😊🎈\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 4 - Historia Sol y Luna\n",
    "\n",
    "prompt = \"¿Qué enseñanza deja ésta historia de los dos gatitos?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0e6cbff-c485-4f13-8496-d9b8256fe18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Sol es un gatito muy valiente y juguetón! 🌞 Le encanta explorar y descubrir cosas nuevas, siempre está listo para una aventura emocionante. 😻🐈\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 5 - Historia Sol y Luna\n",
    "\n",
    "prompt = \"Describime la personalidad de Sol\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8e19caab-ea54-4476-aa71-4cf777d703f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌙 Luna es una gatita muy especial, con un pelaje gris suave como la seda. Es tranquila y le gusta tener su espacio, ¡es una gatita muy elegante y misteriosa! 😻🐈\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 6 - Historia Sol y Luna\n",
    "\n",
    "prompt = \"Describime la personalidad de Luna\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "883c4bfa-d4cf-464d-b3a6-8c0e5110676a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Claro que sí! 🌞🌙 Sol y Luna eran hermanos, nacieron en la misma camada y eran muy diferentes, pero se querían mucho. ¡Una linda familia felina! 😻\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 7 - Historia Sol y Luna\n",
    "\n",
    "prompt = \"¿Sol y Luna eran familiares?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "95889bcf-91d0-4f0c-82aa-dbd8850a077f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐱 Sol y Luna eran muy distintos, ¡como el día y la noche! Sol era aventurero y curioso, mientras que Luna era más tranquila y reservada. 🌞🌛\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 8 - Historia Sol y Luna\n",
    "\n",
    "prompt = \"¿Sol y Luna eran similares en su forma de ser?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be71dd71-fee2-4d43-8c33-c94b900b09e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Sol aprendió que la paciencia y la calma son superpoderosas! 🌞🌙 Descubrió que, a pesar de sus diferencias, él y Luna podían apoyarse mutuamente. 💪🌟\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 9 - Historia Sol y Luna\n",
    "\n",
    "prompt = \"¿A qué aprendio Sol con el paso del tiempo?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e44b6b2-e078-4c07-a744-4715ce4d6f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Después de la tormenta, Sol y Luna se relajaron junto al fuego! 🌞🌙 Se dieron cuenta de que su amistad era muy especial y que podían apoyarse mutuamente. 💛 Un gran aprendizaje para ambos. 😊\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 10 - Historia Sol y Luna\n",
    "\n",
    "prompt = \"¿Qué hicieron Sol y Luna luego del día tormentoso?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34a83e45-45f6-4809-895e-7175d68f1a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐢 Tica es una tortuga muy especial que vive en un estanque rodeado de naturaleza. ¡Es una amiga muy tranquila y sabia! 🌿🌞\n"
     ]
    }
   ],
   "source": [
    "#_____________________________________________#\n",
    "#Uso - Prueba 1 - Historia \"La tortuga Tica\"\n",
    "\n",
    "prompt = \"¿Quién es la tortuga Tica?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3874cad1-6f91-40dd-bafc-63796cfb63c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐢 ¡La tortuga Tica tuvo que renunciar a la tranquilidad de su estanque para embarcarse en una gran aventura! Pero no te preocupes, al final aprendió que ayudar a los demás es una gran recompensa. ¡Un viaje lleno de emociones! 😊🌟\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 2 - Historia \"La tortuga Tica\"\n",
    "\n",
    "prompt = \"¿A que tuvo que renunciar la tortuga cuando decidió irse?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "031754db-edd2-4414-82e5-6969457d5d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐢 Tica era una tortuga muy especial y única, ¡no había otra como ella en el estanque! 🌳 Ella era diferente y eso la hacía muy interesante. 😊\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 3 - Historia \"La tortuga Tica\"\n",
    "\n",
    "prompt = \"¿La tortuga Tica era parecida a sus compañeras?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c7564693-0a5f-4035-9277-80d3b35f945f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐢 ¡La tortuga Tica decidió embarcarse en un viaje emocionante! Descubrió que podía ayudar a otros y hacer nuevos amigos en el camino. ¡Una gran aventura la esperaba! 😊🌍\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 4 - Historia \"La tortuga Tica\"\n",
    "\n",
    "prompt = \"¿Qué decidió un día la tortuga?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f0dd8709-b9d6-44c9-b659-8674e68c1255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐢 ¡Tica encontró un nuevo amigo en su viaje! También descubrió que ayudar a los demás es una gran aventura. ¡Un viaje lleno de sorpresas y lecciones! 😊\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 5 - Historia \"La tortuga Tica\"\n",
    "\n",
    "prompt = \"¿Qué encontró la tortuga durante su viaje?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "743c7dd2-0e95-4ba9-aba8-9305d84dac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐢 ¡Tica estaba emocionada al encontrar el riachuelo! Pensó: \"¡Un nuevo camino por explorar, qué aventura más emocionante!\" 🌊🌳🎢\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 6 - Historia \"La tortuga Tica\"\n",
    "\n",
    "prompt = \"¿Qué pensó la tortuga Tica cuando encontró un riachuelo?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "983c3a59-726b-4266-a6e5-fbf72275f07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡La tortuga Tica se embarcó en un viaje para descubrir nuevos lugares y hacer nuevos amigos! 🌍🐢 En el camino, aprendió que ayudar a los demás es tan importante como explorar el mundo. 🦋🌟\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 7 - Historia \"La tortuga Tica\"\n",
    "\n",
    "prompt = \"¿Cual fue la misión del viaje de la tortuga?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "84ae994f-baf2-4fab-8f7c-77501a00a86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐢 En su viaje, Tica encontró a un amiguito herido y le ayudó a sentirse mejor. ¡Fue una gran aventura y una linda amistad! 😊🌟\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 8 - Historia \"La tortuga Tica\"\n",
    "\n",
    "prompt = \"¿Quién estaba herido en el camino de la tortuga Tica?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d2e0f19-646e-41b4-9d6f-40b6bfc5151c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐢 En su viaje, Tica encontró a un amigo herido que necesitaba ayuda. ¡Ella fue una gran amiga y lo cuidó hasta que se recuperó! 🌟\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 9 - Historia \"La tortuga Tica\"\n",
    "\n",
    "prompt = \"¿Quién estaba herido en el camino de la tortuga Tica?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9d181e50-0678-47f2-a260-00c7c90702ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐢 ¡Los amigos de Tica cuidaron del animalito herido! Ellos fueron muy amables y se aseguraron de que estuviera bien. ¡Un gran equipo de ayuda! 😊🌟\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 10 - Historia \"La tortuga Tica\"\n",
    "\n",
    "prompt = \"¿Quiénes ayudaron a cuidar al animal herido de la tortuga cuando ella se fue?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6aee15aa-a107-462a-b25e-f1c06f593c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧚‍♀️ Puck vivía en un mágico bosque encantado, donde las hadas y la naturaleza lo rodeaban. ¡Un lugar lleno de aventuras y diversión! 🌳🌼🦋\n"
     ]
    }
   ],
   "source": [
    "#_____________________________________________#\n",
    "#Uso - Prueba 1 - Historia \"El Duende\"\n",
    "prompt = \"¿Dónde vivia el pequeño Puck?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "63918a3a-f1b3-4539-bad5-03f7476c0c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡A Puck le encanta hacer bromas y usar su magia para divertirse! 🧚‍♂️🤣 Pero también es muy amable y quiere arreglar las cosas cuando se da cuenta de que su broma fue demasiado lejos. 😊🌟\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 2 - Historia \"El Duende\"\n",
    "\n",
    "prompt = \"¿Qué le gusta hacer a Puck?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a2a4e8d4-b3ba-4d9e-98d6-1364b017e216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧚‍♂️ Puck solo quería divertirse y hacer una broma, pero se dio cuenta de que podía haber causado problemas. ¡Así que decidió arreglar las cosas y ayudar al hada! 🌟🤗\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 3 - Historia \"El Duende\"\n",
    "\n",
    "prompt = \"¿Consideras que Puck tenia buenas o malas intenciones?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e9072be6-013f-4220-b9e3-7f252552253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧚‍♀️ ¡Ella es un hada muy especial para Puck! 🧚‍♂️ Puck quería hacerle una broma, pero se dio cuenta de que debía solucionar las cosas y hacer que todo volviera a la normalidad. 😊\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 4 - Historia \"El Duende\"\n",
    "\n",
    "prompt = \"¿Quién es Ella para Puck?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "834babb9-d6f4-4361-a09d-be21a6435036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧚‍♀️ ¡Hola! El hada 'Ella' es muy sabia y ha vivido muchas aventuras, pero su edad exacta es un misterio. ¡Lo importante es que siempre está lista para compartir su magia y risas con cariño! 😊🌟\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 5 - Historia \"El Duende\"\n",
    "\n",
    "prompt = \"¿Cuántos años tiene el hada 'Ella'?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f943350c-d44f-4b53-ab8d-adf26fd54224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puck se divertía mucho haciendo bromas 🤣, pero cuando vio que la hada estaba confundida, se sintió culpable 😔. ¡Así que decidió arreglar las cosas con un toque de magia! 🧙‍♀️\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 6 - Historia \"El Duende\"\n",
    "\n",
    "prompt = \"¿Cómo se sentía Puck cuando hacía muchas bromas?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "740371de-eaa6-4f1e-8989-8c81b02befd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Claro que sí! Puck usó su magia para hacer que las hojas se movieran y así alegrar a la hada 🧚‍♀️🌿🎆. ¡Fue un gesto muy lindo de su parte! 😊\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 7 - Historia \"El Duende\"\n",
    "\n",
    "prompt = \"¿Puck usó su magia para alegrar al hada 'Ella'?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "90d22b80-bc8f-4c2a-b63b-0e52cb330e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧚‍♀️ ¡El hada 'Ella' sonrió porque aprendió que las risas son más bonitas cuando se comparten con amor y amabilidad! 😊🌟 Una lección muy valiosa para recordar siempre. 🌈\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 8 - Historia \"El Duende\"\n",
    "\n",
    "prompt = \"¿Porqué sonrió el hada 'Ella'?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "faf6778d-6bc1-441f-b45c-48b3fed98981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧚‍♀️ Puck aprendió que las bromas son divertidas, ¡pero también hay que ser amable y pensar en los demás! 🌼 Con el tiempo, entendió que sus travesuras podían tener un lado positivo y hacer sonreír a la gente. 🌟 ¡Un gran aprendizaje para un travieso hada! 😊\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 8 - Historia \"El Duende\"\n",
    "\n",
    "prompt = \"¿Qué aprendió Puck con el paso del tiempo?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8e835306-ac9d-4789-b943-bd2456d5ecae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧚‍♀️ Puck aprendió que las bromas son geniales, pero también hay que ser amable y pensar en los sentimientos de los demás. ¡Una lección muy valiosa para un travieso como él! 🌼🌟\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 9 - Historia \"El Duende\"\n",
    "\n",
    "prompt = \"¿Qué enseñanza le dejó el hada 'Ella' a Puck?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3b8ff5f3-96c3-445a-9b0b-58f04635bb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Las risas son más valiosas cuando se comparten con cariño y respeto, amiguito! 😊🤗 La sabia hada le enseñó a la traviesa que la amabilidad y la diversión van de la mano. 😇🌟\n"
     ]
    }
   ],
   "source": [
    "#Uso - Prueba 10 - Historia \"El Duende\"\n",
    "\n",
    "prompt = \"¿Cuándo son más valiosas las risas según el hada?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fb3358ab-64b3-43d4-b108-7ae48e39eac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lo siento, pequeño amigo, pero esta historia no habla sobre el Mundial de fútbol. 🌟🤔 Aquí se cuenta la aventura de un hada y un travieso Puck. ⚽️🧚‍♀️\n"
     ]
    }
   ],
   "source": [
    "#_____________________________________________#\n",
    "#Pruebas diferentes al contexto para corroborar que repsonda correctamente\n",
    "#Uso - Prueba 1 -\n",
    "\n",
    "prompt = \"¿Quién gana el Mundial de futbol en 2026?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ed3de2e5-f970-4a2f-a2e7-27735d7abaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lo siento, pequeño explorador, pero en esta historia no se menciona la Casa Blanca. 🏠 ¡Pero estoy seguro de que hay muchas aventuras y lugares mágicos por descubrir en este cuento! 😊🧚‍♂️\n"
     ]
    }
   ],
   "source": [
    "#Pruebas diferentes al contexto para corroborar que repsonda correctamente\n",
    "#Uso - Prueba 2 -\n",
    "\n",
    "prompt = \"¿Qué es la casa blanca?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1c684b8b-19d8-469d-9d97-43b2c32695b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lo siento, amigo, pero en esta historia no se trata de elecciones ni de presidentes. ¡Es una aventura mágica llena de risas y diversión! 😊🧚‍♀️🤩\n"
     ]
    }
   ],
   "source": [
    "#Pruebas diferentes al contexto para corroborar que repsonda correctamente\n",
    "#Uso - Prueba 2 -\n",
    "\n",
    "prompt = \"¿Quién gano la presidencia en la historia?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "561481d3-01e6-40a7-8afc-50a11cf70e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puck vivía en lo profundo del bosque 🌲🧚‍♂️, un lugar mágico y lleno de aventuras. ¡Ahí es donde este travieso duende hacía de las suyas! 😄\n"
     ]
    }
   ],
   "source": [
    "#Pruebas diferentes idiomas para asegurar que responda en español\n",
    "#Uso - Prueba 1 -\n",
    "\n",
    "prompt = \"Where did Puck lived?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e5b2ad79-c911-4bf1-81cc-07f1cac330e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧚‍♂️ ¡Hola! Puck vivía en un lugar mágico, en el mundo de las hadas y la fantasía. 🌟🌿 Un lugar lleno de sorpresas y diversión.\n"
     ]
    }
   ],
   "source": [
    "#Pruebas diferentes idiomas para asegurar que responda en español\n",
    "#Uso - Prueba 2 -\n",
    "\n",
    "prompt = \"Où vivait Puck?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2479356b-7739-4b57-97bd-9249b996603b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐢 Tica es una tortuga muy especial que vive en un estanque rodeado de naturaleza. ¡Es la protagonista de esta historia y tiene muchas aventuras por descubrir! 😊\n"
     ]
    }
   ],
   "source": [
    "#Pruebas diferentes idiomas para asegurar que responda en español\n",
    "#Uso - Prueba 3 -\n",
    "\n",
    "prompt = \"¿Who is the turtle 'Tica'?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "22ade61d-b035-4787-a5d2-17ae679c59ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌟 ¡Hola! Tica es una tortuga que vive en un estanque muy bonito, rodeada de árboles 🌳. Es la protagonista de esta historia tan divertida! 😊\n"
     ]
    }
   ],
   "source": [
    "#Pruebas diferentes idiomas para asegurar que responda en español\n",
    "#Uso - Prueba 4 -\n",
    "\n",
    "prompt = \"Qui est la tortue 'Tica'?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "70a2785a-8e17-40e5-b42f-d5c765459233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧚‍♀️ ¡Hola! Pues, en esta historia no se menciona la edad de Ella, pero seguro es una hada muy sabia y experimentada, con muchos años de magia y travesuras a sus espaldas! 🧙‍♀️\n"
     ]
    }
   ],
   "source": [
    "#Pruebas diferentes idiomas para asegurar que responda en español\n",
    "#Uso - Prueba 5 -\n",
    "\n",
    "prompt = \"How old are 'Ella'?\"\n",
    "response = RAG_answer(prompt, collection, system_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef584b8b-2941-401d-9967-d11cd71c0969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
