
# PROYECTO DE RESPUESTAS GENERATIVAS BASADAS EN RECUPERACIN (RAG)

## INTRODUCCIN

En este proyecto utilic茅 t茅cnicas de Recuperaci贸n y Generaci贸n (RAG) para responder preguntas de manera contextualizada. Las respuestas son generadas a partir de un conjunto de historias, extraidas a partir de un documento PDF y almacenadas en una base de datos vectorial utilizando embeddings y modelos de lenguaje. 

El objetivo es ofrecer respuestas consistentes, amigables y personalizadas para cada pregunta del usuario, siguiendo un tono definido.


## TCNOLOGIAS Y HERRAMIENTAS

### **1. PyPDF**
- **Uso**: **PyPDF** es una librer铆a en Python que permite trabajar con archivos PDF de manera sencilla. La utilic茅 para extraer el texto de los documentos en formato PDF, lo cual fue esencial para obtener la informaci贸n necesaria para generar respuestas contextuales y basadas en documentos.
- **Motivo**: La extracci贸n del texto es eficiente, es simple de usar, es compatible tambi茅n en casos de uso de textos en diversos idiomas.

### **2. RecursiveCharacterTextSplitter-Langchain**
- **Uso**: Librer铆a **Langchain** junto con la clase **RecursiveCharacterTextSplitter** para dividir los documentos largos en "chunks" o fragmentos m谩s peque帽os. Esto es fundamental para manejar documentos extensos y procesarlos de manera eficiente, asegurando que el modelo pueda trabajar con ellos sin sobrecargar la memoria o el tiempo de procesamiento.
- **Motivo**: La divisi贸n del texto es eficiente, simple de utilizar y configurar. Langchain proporciona una forma sencilla y flexible de integrar este m茅todo de partici贸n de texto en el flujo de trabajo de procesamiento de documentos, lo que mejora la eficiencia y la escalabilidad del sistema.

### **3. Cohere**
- **Uso**: Generaci贸n de embeddings y respuestas generativas.
- **Motivo**: Utilic茅 el modelo multilingual-v3.0 para generar embeddings multiling眉es de alta calidad, optimizados para manejar texto en varios idiomas. Esto permite comprender preguntas y buscar similitudes sem谩nticas de forma precisa, incluso en diferentes lenguajes. Aunque el modelo soporta m煤ltiples idiomas (importante para comprensi贸n de preguntas en diferentes idiomas), las respuestas se especifican siempre en espa帽ol para garantizar consistencia en la comunicaci贸n.

### **4. ChromaDB**
- **Uso**: Base de datos vectorial para almacenar y recuperar embeddings.
- **Motivo**: Permite b煤squedas eficientes y r谩pidas en un espacio vectorial, ideal para encontrar documentos relevantes basados en similitud sem谩ntica.

### **5. Python**
- **Uso**: Lenguaje principal para la implementaci贸n del flujo RAG.
- **Motivo**: Su amplio ecosistema de bibliotecas y soporte para APIs como Cohere lo hacen ideal para proyectos de IA.

### **6. RAG (Retrieve-Answer-Generate)**
- **Uso**: Arquitectura utilizada para responder preguntas.
- **Motivo**: Combina lo mejor de la recuperaci贸n de informaci贸n (retrieval) y generaci贸n de texto (generation) para ofrecer respuestas precisas y contextualizadas.

## ARQUITECTURA DEL PROYECTO

### **1. Flujo del Sistema**
1. **Generaci贸n de embeddings**:
   - Se utiliza el modelo `embed-multilingual-v3.0` para convertir el texto del prompt y los chunks de la historia en un embedding vectorial.
2. **B煤squeda en la base de datos**:
   - El embedding generado se compara con los almacenados en ChromaDB(embeddings de chunks) para recuperar el documento m谩s relevante.
3. **Generaci贸n de respuesta**:
   - Utilizando el modelo generativo de Cohere, se produce una respuesta personalizada(seg煤n las caracter铆sticas especificadas en system_prompt) basada en el documento relevante.

### **2. Archivos Principales**
- **`RAG.ipynb`**: Contiene el c贸digo estructurado de manera accesible listo para ser ejecutado.
- **`historias.pdf`**: Documento del cual se ha extraido la informaci贸n para pasarle como contexto al modelo.
- **`embeddings.json`**: Directorio que almacena los datos de historias en formato vectorial (Cada embedding con su chunk correspondiente)
- **`README.md`**: Documentaci贸n del proyecto.
- **`requirements.txt`**: Archivo con  librerias necesarias para instalar.

## INSTRUCCIONES DE EJECUCIN
### **1. Requisitos**
- Python 3.8 o superior.

### **3. Instalaci贸n**
1. Clona este repositorio:
   ```
   git clone https://github.com/LuzTappero/Challenge-proyectoRAG
   cd proyecto-rag

2. Creaci贸n de entorno virtual(recomendado):

   - Para crear el entorno: python -m venv venv,
   - Para activar el entorno: .\venv\Scripts\activate

2. Instala las dependencias necesarias en el entorno virtual
   - pip install -r requirements.txt

   - Crear un archivo .env para colocar tu API_KEY de Cohere.

### **3.Ejecuci贸n**
    En la raiz del proyecto desde la terminal ejecutar el comando:
       ```
        jupyter lab

   Esto abrir谩 Jupyter Lab en tu navegador predeterminado accediendo a tu notebook para comenzar la ejecuci贸n.

## EJEMPLO DE USO

   #Uso - prueba 1 - Historia Sol y Luna

   #Definici贸n del prompt

   - prompt = "驴Qui茅nes son Sol y luna?"

   #Llamada a la funci贸n RAG_answer

   - response = RAG_answer(prompt, collection, system_prompt)

   #Obtenci贸n de la respuesta
   - print(response)

隆Sol y Luna son dos adorables gatitos ! Sol es muy valiente y le encanta explorar, mientras que Luna es m谩s tranquila y suave como una nube . 隆Son los mejores amigos y siempre se divierten juntos! 


